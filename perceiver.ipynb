{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lLN5JTga96SM"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import ssl\n",
        "import re\n",
        "import random\n",
        "from urllib import request\n",
        "import cv2\n",
        "import imageio\n",
        "import numpy as np\n",
        "import scipy.io.wavfile\n",
        "import ffmpeg\n",
        "import shutil\n",
        "\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qNELYQzrBFcl"
      },
      "outputs": [],
      "source": [
        "UCF_ROOT_URL = 'https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/'\n",
        "context = ssl._create_unverified_context()\n",
        "\n",
        "def ucf_label2name_dict():\n",
        "  idx = request.urlopen(UCF_ROOT_URL, context=context).read().decode('utf-8')\n",
        "  videos = sorted(list(set(re.findall('(v_[\\w_]+\\.avi)', idx))))\n",
        "  output = {}\n",
        "  for video in videos:\n",
        "    label = re.findall('v_(.*)_g', video)[0]\n",
        "    output.setdefault(label, []).append(video)\n",
        "  return output\n",
        "\n",
        "def fetch_ucf_video(video, destination):\n",
        "  urlpath = request.urljoin(UCF_ROOT_URL, video)\n",
        "  print(f'Fetching {urlpath} -> {destination}')\n",
        "  data = request.urlopen(urlpath, context=context).read()\n",
        "  open(destination, \"wb\").write(data)\n",
        "  return destination\n",
        "\n",
        "def prepare_ucf_dataset(destination='ucf101', num_per_class=None, random_sample=False):\n",
        "  cnt = 0\n",
        "  for label, videos in ucf_label2name_dict().items():\n",
        "    if num_per_class:\n",
        "      if random_sample:\n",
        "        videos = random.sample(videos, num_per_class)\n",
        "      else:\n",
        "        videos = videos[:num_per_class]\n",
        "    for video in videos:\n",
        "      data_name = re.findall('(.*).avi', video)[0]\n",
        "      data_dir = os.path.join(destination, label, data_name)\n",
        "      os.makedirs(data_dir, exist_ok=True)\n",
        "      video_dest = os.path.join(data_dir, video)\n",
        "      audio_dest = os.path.join(data_dir, video.replace('.avi', '.wav'))\n",
        "      if not os.path.exists(video_dest):\n",
        "        fetch_ucf_video(video, video_dest)\n",
        "        try:\n",
        "          ffmpeg.run(ffmpeg.output(ffmpeg.input(video_dest), audio_dest))\n",
        "        except:\n",
        "          shutil.rmtree(os.path.join(destination, label))\n",
        "          break\n",
        "        cnt += 1\n",
        "  return cnt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.5h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzxIPJDdMTOo",
        "outputId": "c71cc17d-b31e-4242-9697-41677d3f79f2"
      },
      "outputs": [],
      "source": [
        "print('video count:', prepare_ucf_dataset(num_per_class=50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ApplyEyeMakeup 50\n",
            "ApplyLipstick 50\n",
            "Archery 50\n",
            "BabyCrawling 50\n",
            "BalanceBeam 50\n",
            "BandMarching 50\n",
            "BasketballDunk 50\n",
            "BlowDryHair 50\n",
            "BlowingCandles 50\n",
            "BodyWeightSquats 50\n",
            "Bowling 50\n",
            "BoxingPunchingBag 50\n",
            "BoxingSpeedBag 50\n",
            "BrushingTeeth 50\n",
            "CliffDiving 50\n",
            "CricketBowling 50\n",
            "CricketShot 50\n",
            "CuttingInKitchen 50\n",
            "FieldHockeyPenalty 50\n",
            "FloorGymnastics 50\n",
            "FrisbeeCatch 50\n",
            "FrontCrawl 50\n",
            "Haircut 50\n",
            "HammerThrow 50\n",
            "Hammering 50\n",
            "HandstandPushups 50\n",
            "HandstandWalking 50\n",
            "HeadMassage 50\n",
            "IceDancing 50\n",
            "Knitting 50\n",
            "LongJump 50\n",
            "MoppingFloor 50\n",
            "ParallelBars 50\n",
            "PlayingCello 50\n",
            "PlayingDaf 50\n",
            "PlayingDhol 50\n",
            "PlayingFlute 50\n",
            "PlayingSitar 50\n",
            "Rafting 50\n",
            "ShavingBeard 50\n",
            "Shotput 50\n",
            "SkyDiving 50\n",
            "SoccerPenalty 50\n",
            "StillRings 50\n",
            "SumoWrestling 50\n",
            "Surfing 50\n",
            "TableTennisShot 50\n",
            "Typing 50\n",
            "UnevenBars 50\n",
            "WallPushups 50\n",
            "WritingOnBoard 50\n"
          ]
        }
      ],
      "source": [
        "for label in sorted(os.listdir('ucf101')):\n",
        "    print(label, len(os.listdir(os.path.join('ucf101', label))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "DRDJAg5kUK33"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def crop_center_square(frame):\n",
        "  h, w = frame.shape[0:2]\n",
        "  min_dim = min(h, w)\n",
        "  sx = (w//2) - (min_dim//2)\n",
        "  sy = (h//2) - (min_dim//2)\n",
        "  return frame[sy : sy+min_dim, sx : sx+min_dim]\n",
        "\n",
        "def load_video(path, max_time=None, resize=(224, 224)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames=[]\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret: break\n",
        "      # frame = crop_center_square(frame)\n",
        "      # frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "      if max_time:\n",
        "        if cap.get(cv2.CAP_PROP_POS_MSEC) * 1e-3 >= max_time:\n",
        "          break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return torch.tensor(frames) / 255.0\n",
        "\n",
        "def load_audio(path, max_time=None):\n",
        "  waveform, sample_rate = torchaudio.load(path)\n",
        "  if max_time:\n",
        "    max_frame = int(max_time * sample_rate)\n",
        "    waveform = waveform[:, :max_frame]\n",
        "  return waveform, sample_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def loader(path, max_time):\n",
        "  datum = os.listdir(path)\n",
        "  for data in datum:\n",
        "    if data.endswith('.avi'):\n",
        "      video = load_video(os.path.join(path, data), max_time=max_time)\n",
        "    elif data.endswith('.wav'):\n",
        "      audio, _ = load_audio(os.path.join(path, data), max_time=max_time)\n",
        "  return video, audio\n",
        "\n",
        "\n",
        "class UCFDataset(DatasetFolder):\n",
        "  def __init__(self, root, loader, max_time=None):\n",
        "    self.root = root\n",
        "    self.loader = loader\n",
        "    self.max_time = max_time\n",
        "    self.classes, self.class_to_idx = super().find_classes(root)\n",
        "    self.samples = self.make_dataset(self.root, self.class_to_idx)\n",
        "\n",
        "  def make_dataset(self, directory, class_to_idx):\n",
        "    instances = []\n",
        "    for target_class in sorted(class_to_idx.keys()):\n",
        "      class_idx = class_to_idx[target_class]\n",
        "      target_dir = os.path.join(directory, target_class)\n",
        "      if not os.path.isdir(target_dir):\n",
        "        continue\n",
        "      for data_name in sorted(os.listdir(target_dir)):\n",
        "        path = os.path.join(target_dir, data_name)\n",
        "        item = path, class_idx\n",
        "        instances.append(item)\n",
        "    return instances\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    path, target = self.samples[idx]\n",
        "    sample = self.loader(path, self.max_time)\n",
        "    return sample, target\n",
        "\n",
        "\n",
        "class SetTransform(Dataset):\n",
        "  def __init__(self, dataset, transform):\n",
        "    self.dataset = dataset\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    (video, audio), label = self.dataset[idx]\n",
        "    video = self.transform(video)\n",
        "    return (video, audio), label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_dataset = UCFDataset('ucf101', loader=loader, max_time=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([125, 240, 320, 3])\n",
            "torch.Size([2, 220500])\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "(video, audio), label = all_dataset[0]\n",
        "print(video.shape)\n",
        "print(audio.shape)\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "lab-work-gFKfzxI5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "849f61b40a9f0695613f10abe0801a9209e9c807f7f85006c3621f09dc21595f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
